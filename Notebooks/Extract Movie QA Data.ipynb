{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import cPickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a char set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chars = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z',\n",
    "                 '0','1','2','3','4','5','6','7','8','9',\n",
    "                 ' ',',','.',':',';',\"'\",'!','?','$','%','&','(',')','=','+','-']\n",
    "\n",
    "chars_to_idx = {}\n",
    "index = 0\n",
    "for c in chars : \n",
    "    chars_to_idx[c] = index\n",
    "    index += 1\n",
    "    \n",
    "idx_to_chars = {}\n",
    "for k,i in chars_to_idx.items():\n",
    "    idx_to_chars[i] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stringToOneHot(s, chars_to_idx, lower=True):\n",
    "    if lower:\n",
    "        s = s.lower()\n",
    "        \n",
    "    # Add an UNKNOWN char\n",
    "    v_seq = np.zeros((len(s), len(chars_to_idx.keys())+1), dtype=np.float32)\n",
    "    \n",
    "    for i in range(len(s)):\n",
    "        # Is s[i] a known character?\n",
    "        try:\n",
    "            v_seq[i,chars_to_idx[s[i]]] = 1.0\n",
    "        #If not, then unknown = 1\n",
    "        except KeyError:\n",
    "            v_seq[i, -1] = 1.0\n",
    "    return v_seq\n",
    "\n",
    "def oneHotToString(seq, idx_to_chars):\n",
    "    s = \"\"\n",
    "    for one_hot_vec in seq:\n",
    "        # Is the index in idx_to_char?\n",
    "        try:\n",
    "            #print np.argmax(one_hot_vec)\n",
    "            s += idx_to_chars[np.argmax(one_hot_vec)]\n",
    "        except KeyError:\n",
    "            s += '<UNK>'\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conversations : 83097\n",
      "Number of lines : 304713\n"
     ]
    }
   ],
   "source": [
    "movieQA_folder = os.path.join('.','..','Data','MovieQA')\n",
    "\n",
    "# Load text files into nupmy arrays;\n",
    "movie_convs_txt = os.path.join(movieQA_folder, 'movie_conversations.txt')\n",
    "movie_lines_txt = os.path.join(movieQA_folder, 'movie_lines.txt')\n",
    "\n",
    "movie_convs_np = np.loadtxt(movie_convs_txt, dtype='string', delimiter=' +++$+++ ', comments=None)\n",
    "movie_lines_np = np.loadtxt(movie_lines_txt, dtype='string', delimiter=' +++$+++ ', comments=None)\n",
    "\n",
    "print \"Number of conversations : %d\" % len(movie_convs_np)\n",
    "print \"Number of lines : %d\" % len(movie_lines_np) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dictionaries of movie lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lineID : one_hot_sequence\n",
    "line_to_one_hot = {}\n",
    "\n",
    "# lineID : movie character ID\n",
    "line_to_movie_car = {}\n",
    "\n",
    "for line in movie_lines_np:\n",
    "    line_to_one_hot[line[0]] = stringToOneHot(line[-1], default_chars, lower=True)\n",
    "    line_to_movie_car[line[0]] = line[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304713\n",
      "[13 14 38 38 38]\n",
      "unsolved mystery.  she used to be really popular when she started high school, then it was just like she got sick of it or something.\n"
     ]
    }
   ],
   "source": [
    "#Sanity check\n",
    "print len(movie_lines.keys())\n",
    "print np.argmax(movie_lines['L2103'], axis=1)\n",
    "print oneHotToString(movie_lines['L205'], idx_to_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a list of Q/A pairs - AKA the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 221616 Q/A pairs.\n"
     ]
    }
   ],
   "source": [
    "# Create a list of Q/A pairs.\n",
    "#  For the simplest approach. We should be able to train a mediocre language (character-level) model with this.\n",
    "#  Eventually, this dataset could be more usful for a dialogue model, since most conversations have more than 2 interactions.\n",
    "\n",
    "qa_pairs = []\n",
    "for conversation in movie_convs_np:\n",
    "    subID = 0\n",
    "    lines = eval(conversation[-1])\n",
    "    while subID < (len(lines) - 1):\n",
    "        qa_pairs.append((line_to_one_hot[lines[subID]], line_to_one_hot[lines[subID+1]]))\n",
    "        subID += 1\n",
    "print \"Got %d Q/A pairs.\" % len(qa_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "why?\n",
      "unsolved mystery.  she used to be really popular when she started high school, then it was just like she got sick of it or something.\n"
     ]
    }
   ],
   "source": [
    "#Sanity check :\n",
    "idx = 7\n",
    "print oneHotToString(qa_pairs[idx][0], idx_to_chars)\n",
    "print oneHotToString(qa_pairs[idx][1], idx_to_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qa_pairs_pkl = os.path.join(movieQA_folder, 'QA_Pairs.pkl')\n",
    "with open(qa_pairs_pkl, 'wb') as f:\n",
    "    cPickle.dump({\"qa_data\":qa_pairs}, f, protocol=cPickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the pkl dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it means that gigglepuss is playing at club skunk and we're going.\n",
      "oh, i thought you might have a date  i don't know why i'm bothering to ask, but are you going to bogey lowenstein's party saturday night?\n"
     ]
    }
   ],
   "source": [
    "# Sanity check:\n",
    "with open(qa_pairs_pkl, 'rb') as f:\n",
    "    data = cPickle.load(f)\n",
    "qa_pairs = data[\"qa_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i can't talk to anybody right now, can't you see i'm busy!  i can't talk business.  hang up.  have a drink.  get her a whiskey.\n",
      "trust me, you'll want to take this call.\n",
      "\n",
      "i'm running away.\n",
      "you think that's wise?\n",
      "\n",
      "you don't live around here, do you?\n",
      "no, mam... i come from way back there. me and my dog was tryin' to find my daddy and we got lost.\n",
      "\n",
      "dudley, what do you want?\n",
      "lad, i admire your refusal to testify and your loyalty to your partner.  i admire you as a policeman, particularly your adherence to violence as a necessary adjutant to the job. and i am most impressed with your punishment of wife beaters.  do you hate them, wendell?\n",
      "\n",
      "what are ya, deaf?  turn around!\n",
      "no! no don't shoot me i don't want to get shot!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_examples = 5\n",
    "\n",
    "for i in range(n_examples):\n",
    "    idx = np.random.randint(len(qa_pairs))\n",
    "    print oneHotToString(qa_pairs[idx][0], idx_to_chars)\n",
    "    print oneHotToString(qa_pairs[idx][1], idx_to_chars)\n",
    "    print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
